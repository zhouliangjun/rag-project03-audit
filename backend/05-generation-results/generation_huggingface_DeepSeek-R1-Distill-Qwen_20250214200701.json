{
  "query": "What is GRPO",
  "timestamp": "2025-02-14T20:07:01.189871",
  "provider": "huggingface",
  "model": "DeepSeek-R1-Distill-Qwen",
  "response": "æ ¹æ®ä¸Šä¸‹æ–‡ï¼Œé—®é¢˜â€œWhat is GRPOâ€å¯ä»¥ç”±ä¸Šä¸‹æ–‡ä¸­çš„â€œGroup Relative Policy Optimization In order to save the training costs of RLâ€å’Œâ€œSpecifically, for each question ğ‘, GRPO samples a group of outputs {ğ‘œ1, ğ‘œ2, Â· Â· Â· , ğ‘œğº} from the old policy ğœ‹ğœƒğ‘œğ‘™ğ‘‘ and then optimizes the policy model ğœ‹ğœƒ by maximizing the following objectiveâ€å¾—å‡ºã€‚å› æ­¤ï¼ŒGRPOæŒ‡çš„æ˜¯é€šè¿‡ç¾¤ç»„å¾—åˆ†çš„å¹³å‡æ¥ä¼°è®¡åŸºå‡†ï¼Œä»è€Œä¼˜åŒ–æ”¿ç­–çš„æ–¹æ³•ã€‚å› æ­¤ï¼Œé—®é¢˜çš„ç­”æ¡ˆæ˜¯GRPOæ˜¯Group Relative Policy Optimizationï¼Œç”¨äºå‡å°‘RLè®­ç»ƒæˆæœ¬çš„æ–¹æ³•ï¼ŒåŸºäºä¸Šæ–‡ä¸­çš„ä¿¡æ¯ï¼Œå¯ä»¥ç¡®å®šè¿™æ˜¯ä¸€ä¸ªä¼˜åŒ–æ–¹æ³•ï¼Œç”¨äºå‡å°‘RLçš„è®­ç»ƒæˆæœ¬ã€‚\n</think>\n\nGroup Relative Policy Optimization (GRPO) is an optimization method introduced by Shao et al. (2024) to reduce the training costs of reinforcement learning (RL). It avoids the need for a critic model that is typically the same size as the policy model by estimating the baseline based on group scores. Specifically, for each question \\( q \\), GRPO samples a group of outputs \\( \\{o_1, o_2, \\ldots, o_G\\} \\) from the old policy \\( \\pi_{\\text{old}} \\) and optimizes the policy model \\( \\pi \\) to maximize the following objective.\n\nTherefore, the answer is GRPO is Group Relative Policy Optimization, a method used to reduce the training costs of RL by estimating the baseline from group scores.\n\n\\boxed{GRPO}",
  "context": [
    {
      "text": "Group Relative Policy Optimization In order to save the training costs of RL, we adopt Group Relative Policy Optimization (GRPO) (Shao et al., 2024), which foregoes the critic model that is typically the same size as the policy model, and estimates the baseline from group scores instead. Specifically, for each question ğ‘, GRPO samples a group of outputs {ğ‘œ1, ğ‘œ2, Â· Â· Â· , ğ‘œğº} from the old policy ğœ‹ğœƒğ‘œğ‘™ğ‘‘ and then optimizes the policy model ğœ‹ğœƒ by maximizing the following objective:",
      "score": 0.5254793167114258,
      "metadata": {
        "source": "DeepSeek_R1.pdf",
        "page": "5",
        "chunk": 41,
        "total_chunks": 180,
        "page_range": "5",
        "embedding_provider": "openai",
        "embedding_model": "text-embedding-3-small",
        "embedding_timestamp": "2025-02-14T16:48:03.946618"
      }
    }
  ]
}